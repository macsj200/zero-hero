{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "938af232-6712-4ea5-9e88-a440c0b7444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61b58a47-27f0-4aa4-8cf1-44076e7dbc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/names.txt\") as f:\n",
    "    names = f.read().splitlines()\n",
    "random.shuffle(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23993246-45d4-4e65-a1f0-7a7273a1cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngram(s, n):\n",
    "    res = []\n",
    "    l = ['.'] + list(s) + ['.']\n",
    "    for i in range(len(l)-n+1):\n",
    "        res.append(tuple(l[i:i+n]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9bed38a-8f11-4ba3-a37d-456f3f5e2948",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctoi = {chr(ord('a') + i): i+1 for i in range(26)}\n",
    "ctoi['.'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f42d6dc0-bf15-4557-aabe-ed228869c05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "itoc = {v: k for k,v in ctoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb1e71d7-b1c7-4818-9ebe-f5f1a356205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = [], []\n",
    "for s in names:\n",
    "    for ngram in build_ngram(s, 3):\n",
    "        x = ngram[0:2]\n",
    "        y = ngram[2]\n",
    "        xs.append((ctoi[x[0]], ctoi[x[1]]))\n",
    "        ys.append(ctoi[y])\n",
    "xs, ys = torch.tensor(xs), torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82e6ac15-2ab8-4390-bf0b-d5ed2800b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = int(ys.shape[0] * .8)\n",
    "ndev = int(ys.shape[0] * .9)\n",
    "\n",
    "x_train, y_train = xs[:ntrain], ys[:ntrain]\n",
    "x_dev, y_dev = xs[ntrain:ndev], ys[ntrain:ndev]\n",
    "x_test, y_test = xs[ndev:], ys[ndev:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97447a08-e09b-4bc7-a123-623b9abeb3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2937092781066895\n",
      "2.2731430530548096\n",
      "2.2601845264434814\n",
      "2.256619930267334\n",
      "2.2551889419555664\n"
     ]
    }
   ],
   "source": [
    "xenc = F.one_hot(x_train, num_classes=27).float()\n",
    "W = torch.randn((27*2, 27), requires_grad=True)\n",
    "for k in range(500):\n",
    "    logits = xenc.view(-1,27*2) @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdims=True)\n",
    "    loss = -probs[torch.arange(y_train.shape[0]), y_train].log().mean() + 0.01*(W**2).mean()\n",
    "    if k % 100 == 0:\n",
    "        print(loss.item())\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "adc819f0-56d6-4006-b6f3-7f28bba0746c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.255495309829712 2.255495309829712\n"
     ]
    }
   ],
   "source": [
    "xenc = F.one_hot(x_test, num_classes=27).float()\n",
    "logits = xenc.view(-1,27*2) @ W\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "loss = -probs[torch.arange(y_test.shape[0]), y_test].log().mean() + 0.01*(W**2).mean()\n",
    "print(loss.item(), (F.cross_entropy(logits, y_test) + 0.01*(W**2).mean()).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16cf9026-c660-4e6f-b23a-71654c9aeed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2494254112243652\n"
     ]
    }
   ],
   "source": [
    "xenc = F.one_hot(x_dev, num_classes=27).float()\n",
    "logits = xenc.view(-1,27*2) @ W\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "loss = -probs[torch.arange(y_dev.shape[0]), y_dev].log().mean() + 0.01*(W**2).mean()\n",
    "print(loss.item())\n",
    "\n",
    "# .01 2.257039785385132\n",
    "# .001 2.258058786392212\n",
    "# .1 2.2723448276519775\n",
    "# .0001 2.2585158348083496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80c82347-6370-4382-a087-1ef251791811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orteliasin.\n",
      "olishirahan.\n",
      "uon.\n",
      "uan.\n",
      "myrla.\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    out = ['.', '.']\n",
    "    ix = 0\n",
    "    while True:\n",
    "        xenc_in = F.one_hot(torch.tensor([(ctoi[out[-2]], ctoi[out[-1]])]), num_classes=27).float()\n",
    "        logits = xenc_in.view(-1, 27*2) @ W\n",
    "        counts = logits.exp()\n",
    "        probs = counts / counts.sum(1, keepdims=True)\n",
    "        ix = torch.multinomial(probs, num_samples=1, replacement=True).item()\n",
    "        out.append(itoc[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(\"\".join(out[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d0a64b-31c0-4c15-98d4-4909958b03a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
